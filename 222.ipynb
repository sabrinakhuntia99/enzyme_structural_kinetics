{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pyvista as pv\n",
    "from Bio.PDB import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from molecular_extraction_functions import conv_array_text, extract_N_and_CA_backbone_atoms\n",
    "from ripser import ripser\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial import ConvexHull\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Constants\n",
    "MAX_POINTS = 200  # Max points to sample for topology\n",
    "\n",
    "# Load and preprocess coordinate data\n",
    "data_df = pd.read_csv(\n",
    "    r\"C:\\Users\\Sabrina\\Documents\\GitHub\\protein_structural_kinetics\\data\\pep_cleave_coordinates_10292023.csv\",\n",
    "    index_col=0)\n",
    "data_df = data_df.applymap(conv_array_text)\n",
    "data_df = data_df[0:1000]\n",
    "\n",
    "# Output structural dictionary\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-15T19:12:49.448219Z",
     "start_time": "2025-04-15T19:12:44.861946Z"
    }
   },
   "id": "b2076574f09d3dba",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "num_proteins = len(data_df.index)\n",
    "structural_properties = {\n",
    "    'betti_0': np.zeros(num_proteins),\n",
    "    'betti_1': np.zeros(num_proteins),\n",
    "    'hull_presence': np.zeros(num_proteins),\n",
    "}\n",
    "for i in range(1, 11):\n",
    "    structural_properties[f'lys_arg_layer_{i}'] = np.zeros(num_proteins)\n",
    "\n",
    "# Add per-timepoint hull presence\n",
    "timepoint_columns = list(data_df.columns[1:])\n",
    "for col in timepoint_columns:\n",
    "    structural_properties['hull_presence_' + col] = np.zeros(num_proteins)\n",
    "\n",
    "# Load PDB paths\n",
    "def get_pdb_file_paths(folder_path):\n",
    "    pdb_paths = {}\n",
    "    pattern = re.compile(r\"AF-(\\w+)-F\\d+-model_v4.pdb\")\n",
    "    for subdir, _, files in os.walk(folder_path):\n",
    "        match = pattern.match(os.path.basename(subdir))\n",
    "        if match:\n",
    "            uniprot_id = match.group(1)\n",
    "            pdb_files = [f for f in files if f.endswith('.pdb')]\n",
    "            if pdb_files:\n",
    "                pdb_paths[uniprot_id] = os.path.join(subdir, pdb_files[0])\n",
    "    return pdb_paths\n",
    "\n",
    "pdb_paths_dict = get_pdb_file_paths(r\"C:\\Users\\Sabrina\\PycharmProjects\\intrinsic_disorder\\proteome_human\")\n",
    "parse = PDBParser()\n",
    "\n",
    "# Calculate overall distribution of hull radii to define dynamic layers\n",
    "all_hull_radii = []\n",
    "\n",
    "# Loop through proteins to calculate all hull radii for global statistics\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-15T19:13:02.540404Z",
     "start_time": "2025-04-15T19:12:51.437641Z"
    }
   },
   "id": "d5ddbdfb0b31cb1b",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for idx, uniprot_id in enumerate(data_df.index):\n",
    "    try:\n",
    "        pdb_file_path = pdb_paths_dict.get(uniprot_id)\n",
    "        if pdb_file_path is None or not os.path.isfile(pdb_file_path):\n",
    "            continue\n",
    "\n",
    "        structure = parse.get_structure(uniprot_id, pdb_file_path)\n",
    "        points = extract_N_and_CA_backbone_atoms(structure)\n",
    "        hull = ConvexHull(points)\n",
    "        centroid = np.mean(points, axis=0)\n",
    "        hull_distances = [np.linalg.norm(point - centroid) for point in points[hull.vertices]]\n",
    "        all_hull_radii.extend(hull_distances)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {uniprot_id}: {e}\")\n",
    "\n",
    "# Global hull radius statistics\n",
    "all_hull_radii = np.array(all_hull_radii)\n",
    "mean_hull_radius = np.mean(all_hull_radii)\n",
    "std_hull_radius = np.std(all_hull_radii)\n",
    "\n",
    "# Function to determine the number of dynamic layers\n",
    "def determine_num_layers(hull_radius, mean_radius, std_radius):\n",
    "    thresholds = [\n",
    "        mean_radius - 2 * std_radius,\n",
    "        mean_radius - 1.5 * std_radius,\n",
    "        mean_radius - std_radius,\n",
    "        mean_radius - 0.5 * std_radius,\n",
    "        mean_radius,\n",
    "        mean_radius + 0.5 * std_radius,\n",
    "        mean_radius + std_radius,\n",
    "        mean_radius + 1.5 * std_radius,\n",
    "        mean_radius + 2 * std_radius,\n",
    "    ]\n",
    "    for layer, threshold in enumerate(thresholds, start=1):\n",
    "        if hull_radius < threshold:\n",
    "            return layer\n",
    "    return 10  # Default to layer 10 if above all thresholds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-15T19:13:30.042846Z",
     "start_time": "2025-04-15T19:13:06.950084Z"
    }
   },
   "id": "7dc1fc2cbef408c4",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['C9J177', 'G3V5Z7', 'O60361', 'A0A494C1F2', 'A6NMQ3', 'O75153',\n       'H0Y6U5', 'D6RD97', 'A0A0A0MRE9', 'F2Z2Y4',\n       ...\n       'Q96RS6', 'F5GY68', 'S5FZ81', 'Q9HCG8', 'Q9Y4C8', 'Q7Z3J2', 'J3KRB3',\n       'D3DQV9', 'J3QT87', 'A0A087WYF8'],\n      dtype='object', name='uniprot_id', length=1000)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.index"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-15T19:06:33.077601Z",
     "start_time": "2025-04-15T19:06:33.066105Z"
    }
   },
   "id": "c5e617a887bc50ff",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O60361\n",
      "O60361 0.060192108154296875\n",
      "O75153\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 50\u001B[39m\n\u001B[32m     47\u001B[39m structural_properties[\u001B[33m'\u001B[39m\u001B[33mhull_presence\u001B[39m\u001B[33m'\u001B[39m][idx] = max_hull_presence\n\u001B[32m     49\u001B[39m \u001B[38;5;66;03m# Compute topological properties (Betti 0 and 1)\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m50\u001B[39m diagrams = \u001B[43mripser\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpoints\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmaxdim\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdo_cocycles\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m[\u001B[33m'\u001B[39m\u001B[33mdgms\u001B[39m\u001B[33m'\u001B[39m]\n\u001B[32m     51\u001B[39m betti_0 = \u001B[38;5;28mlen\u001B[39m(diagrams[\u001B[32m0\u001B[39m])  \u001B[38;5;66;03m# Betti-0 (connected components)\u001B[39;00m\n\u001B[32m     52\u001B[39m betti_1 = \u001B[38;5;28mlen\u001B[39m(diagrams[\u001B[32m1\u001B[39m])  \u001B[38;5;66;03m# Betti-1 (loops)\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\delaunay\\venv\\Lib\\site-packages\\ripser\\ripser.py:325\u001B[39m, in \u001B[36mripser\u001B[39m\u001B[34m(X, maxdim, thresh, coeff, distance_matrix, do_cocycles, metric, n_perm)\u001B[39m\n\u001B[32m    323\u001B[39m \u001B[38;5;66;03m# Unwrap persistence diagrams\u001B[39;00m\n\u001B[32m    324\u001B[39m dgms = res[\u001B[33m\"\u001B[39m\u001B[33mbirths_and_deaths_by_dim\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m--> \u001B[39m\u001B[32m325\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m dim \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdgms\u001B[49m\u001B[43m)\u001B[49m):\n\u001B[32m    326\u001B[39m     N = \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(dgms[dim]) / \u001B[32m2\u001B[39m)\n\u001B[32m    327\u001B[39m     dgms[dim] = np.reshape(np.array(dgms[dim]), [N, \u001B[32m2\u001B[39m])\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Process each protein\n",
    "for idx, uniprot_id in enumerate(data_df.index):\n",
    "    try:\n",
    "        start = time.time()\n",
    "        pdb_file_path = pdb_paths_dict.get(uniprot_id)\n",
    "        if pdb_file_path is None or not os.path.isfile(pdb_file_path):\n",
    "            continue\n",
    "        print(uniprot_id)\n",
    "        if idx>10:\n",
    "            break\n",
    "        structure = parse.get_structure(uniprot_id, pdb_file_path)\n",
    "        points = extract_N_and_CA_backbone_atoms(structure)\n",
    "        hull = ConvexHull(points)\n",
    "        centroid = np.mean(points, axis=0)\n",
    "        hull_distances = [np.linalg.norm(point - centroid) for point in points[hull.vertices]]\n",
    "        max_hull_radius = max(hull_distances)\n",
    "\n",
    "        # Determine dynamic number of layers and calculate the percentile thresholds\n",
    "        num_layers = determine_num_layers(max_hull_radius, mean_hull_radius, std_hull_radius)\n",
    "        hull_layers = [np.percentile(hull_distances, (i + 1) * (100 / num_layers)) for i in range(num_layers)]\n",
    "\n",
    "        # Compute per-timepoint hull presence and track the maximum\n",
    "        max_hull_presence = 0\n",
    "        for col in timepoint_columns:\n",
    "            coord_array = data_df.loc[uniprot_id, col]\n",
    "            if coord_array:\n",
    "                dists_at_coord = [np.linalg.norm(coord - centroid) for coord in coord_array]\n",
    "                avg_distance = np.average(dists_at_coord)\n",
    "            else:\n",
    "                avg_distance = np.nan\n",
    "\n",
    "            timepoint_hull_presence = 0  # Default if none of the thresholds are met\n",
    "            for layer_idx in range(len(hull_layers)):\n",
    "                if avg_distance < hull_layers[layer_idx]:\n",
    "                    timepoint_hull_presence = layer_idx + 1\n",
    "                    break\n",
    "\n",
    "            # Store the per-timepoint hull presence\n",
    "            structural_properties['hull_presence_' + col][idx] = timepoint_hull_presence\n",
    "\n",
    "            # Update the maximum hull presence encountered\n",
    "            if timepoint_hull_presence > max_hull_presence:\n",
    "                max_hull_presence = timepoint_hull_presence\n",
    "\n",
    "        # Assign the maximum hull presence across all timepoints\n",
    "        structural_properties['hull_presence'][idx] = max_hull_presence\n",
    "\n",
    "        # Compute topological properties (Betti 0 and 1)\n",
    "        diagrams = ripser(points, maxdim=1, do_cocycles=False)['dgms']\n",
    "        betti_0 = len(diagrams[0])  # Betti-0 (connected components)\n",
    "        betti_1 = len(diagrams[1])  # Betti-1 (loops)\n",
    "\n",
    "        # Output topological values\n",
    "        structural_properties['betti_0'][idx] = betti_0\n",
    "        structural_properties['betti_1'][idx] = betti_1\n",
    "\n",
    "        # Lys/Arg counts per layer\n",
    "        num_layers = 10\n",
    "        layer_thresholds = [np.percentile(hull_distances, (i + 1) * 10) for i in range(num_layers)]\n",
    "        lys_arg_counts = [0] * num_layers\n",
    "        for model in structure:\n",
    "            for chain in model:\n",
    "                for res in chain:\n",
    "                    if res.id[0] != ' ' or res.get_resname() not in ['LYS', 'ARG']:\n",
    "                        continue\n",
    "                    if not res.has_id('CA'):\n",
    "                        continue\n",
    "                    dist = np.linalg.norm(res['CA'].get_coord() - centroid)\n",
    "                    for i, t in enumerate(layer_thresholds):\n",
    "                        if dist < t:\n",
    "                            lys_arg_counts[i] += 1\n",
    "                            break\n",
    "\n",
    "        # Output Lys/Arg counts for each layer\n",
    "        for i in range(1, 11):\n",
    "            structural_properties[f'lys_arg_layer_{i}'][idx] = lys_arg_counts[i - 1]\n",
    "        print(uniprot_id, time.time()-start)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {uniprot_id}: {e}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-15T19:14:39.158762Z",
     "start_time": "2025-04-15T19:13:42.879913Z"
    }
   },
   "id": "a4913dc455f17eb1",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e339716b645fa9f9"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O75153\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "uniprot_id = 'O75153'\n",
    "idx = 0\n",
    "pdb_file_path = pdb_paths_dict.get(uniprot_id)\n",
    "\n",
    "print(uniprot_id)\n",
    "\n",
    "structure = parse.get_structure(uniprot_id, pdb_file_path)\n",
    "points = extract_N_and_CA_backbone_atoms(structure)\n",
    "hull = ConvexHull(points)\n",
    "centroid = np.mean(points, axis=0)\n",
    "hull_distances = [np.linalg.norm(point - centroid) for point in points[hull.vertices]]\n",
    "max_hull_radius = max(hull_distances)\n",
    "\n",
    "# Determine dynamic number of layers and calculate the percentile thresholds\n",
    "num_layers = determine_num_layers(max_hull_radius, mean_hull_radius, std_hull_radius)\n",
    "hull_layers = [np.percentile(hull_distances, (i + 1) * (100 / num_layers)) for i in range(num_layers)]\n",
    "\n",
    "# Compute per-timepoint hull presence and track the maximum\n",
    "max_hull_presence = 0\n",
    "for col in timepoint_columns:\n",
    "    coord_array = data_df.loc[uniprot_id, col]\n",
    "    if coord_array:\n",
    "        dists_at_coord = [np.linalg.norm(coord - centroid) for coord in coord_array]\n",
    "        avg_distance = np.average(dists_at_coord)\n",
    "    else:\n",
    "        avg_distance = np.nan\n",
    "\n",
    "    timepoint_hull_presence = 0  # Default if none of the thresholds are met\n",
    "    for layer_idx in range(len(hull_layers)):\n",
    "        if avg_distance < hull_layers[layer_idx]:\n",
    "            timepoint_hull_presence = layer_idx + 1\n",
    "            break\n",
    "\n",
    "    # Store the per-timepoint hull presence\n",
    "    structural_properties['hull_presence_' + col][idx] = timepoint_hull_presence\n",
    "\n",
    "    # Update the maximum hull presence encountered\n",
    "    if timepoint_hull_presence > max_hull_presence:\n",
    "        max_hull_presence = timepoint_hull_presence\n",
    "\n",
    "# Assign the maximum hull presence across all timepoints\n",
    "structural_properties['hull_presence'][idx] = max_hull_presence"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-15T19:18:04.974283Z",
     "start_time": "2025-04-15T19:18:04.479205Z"
    }
   },
   "id": "673506f0f055b486",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Compute topological properties (Betti 0 and 1)\n",
    "import pickle\n",
    "diagrams = ripser(points, maxdim=1, do_cocycles=False)['dgms']\n",
    "betti_0 = len(diagrams[0])  # Betti-0 (connected components)\n",
    "betti_1 = len(diagrams[1])  # Betti-1 (loops)\n",
    "\n",
    "\n",
    "pickle.dump(diagrams, open('ripser_data/%s.pkl'%uniprot_id, 'wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-15T19:24:30.016634Z",
     "start_time": "2025-04-15T19:23:39.825640Z"
    }
   },
   "id": "5c1c60a2999ebe00",
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
